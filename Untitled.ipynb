{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28143cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m     reward_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     89\u001b[0m     reward_o \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mark \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mstate\u001b[49m):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mark \u001b[38;5;241m==\u001b[39m PLAYER_X:\n\u001b[1;32m     93\u001b[0m         update_Q(state, i, reward_x, state)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the Tic-Tac-Toe board\n",
    "EMPTY = 0\n",
    "PLAYER_X = 1\n",
    "PLAYER_O = 2\n",
    "\n",
    "# Initialize Q-value table\n",
    "num_states = 3 ** 9  # Total number of possible board configurations\n",
    "num_actions = 9      # Number of possible moves\n",
    "Q = np.zeros((num_states, num_actions))\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "exploration_prob = 0.1\n",
    "num_episodes = 10000\n",
    "\n",
    "# Convert board state to a unique index\n",
    "def state_to_index(state):\n",
    "    index = 0\n",
    "    for i, mark in enumerate(state):\n",
    "        index += mark * (3 ** i)\n",
    "    return index\n",
    "\n",
    "# Choose an action based on epsilon-greedy policy\n",
    "def choose_action(state):\n",
    "    if random.random() < exploration_prob:\n",
    "        return random.choice([action for action, mark in enumerate(state) if mark == EMPTY])\n",
    "    else:\n",
    "        return np.argmax(Q[state_to_index(state)])\n",
    "\n",
    "# Update Q-values using Q-learning update rule\n",
    "def update_Q(state, action, reward, next_state):\n",
    "    Q[state_to_index(state)][action] += learning_rate * (reward + discount_factor * np.max(Q[state_to_index(next_state)]) - Q[state_to_index(state)][action])\n",
    "\n",
    "# Play a game using Q-learning\n",
    "def play_game():\n",
    "    state = [EMPTY] * 9\n",
    "    player_x_turn = True\n",
    "    while EMPTY in state:\n",
    "        if player_x_turn:\n",
    "            player = PLAYER_X\n",
    "        else:\n",
    "            player = PLAYER_O\n",
    "            \n",
    "        if player == PLAYER_X:\n",
    "            action = choose_action(state)\n",
    "        else:\n",
    "            action = random.choice([action for action, mark in enumerate(state) if mark == EMPTY])\n",
    "        \n",
    "        state[action] = player\n",
    "        \n",
    "        if check_winner(state, player):\n",
    "            return player\n",
    "        \n",
    "        player_x_turn = not player_x_turn\n",
    "    \n",
    "    return 0  # Draw\n",
    "\n",
    "# Check if a player has won\n",
    "def check_winner(state, player):\n",
    "    winning_combinations = [\n",
    "        [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
    "        [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
    "        [0, 4, 8], [2, 4, 6]             # Diagonals\n",
    "    ]\n",
    "    \n",
    "    for combo in winning_combinations:\n",
    "        if all(state[i] == player for i in combo):\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Train the Q-learning agent\n",
    "for episode in range(num_episodes):\n",
    "    winner = play_game()\n",
    "    \n",
    "    # Update Q-values based on game outcome\n",
    "    if winner == PLAYER_X:\n",
    "        reward_x = 1\n",
    "        reward_o = -1\n",
    "    elif winner == PLAYER_O:\n",
    "        reward_x = -1\n",
    "        reward_o = 1\n",
    "    else:\n",
    "        reward_x = 0\n",
    "        reward_o = 0\n",
    "    \n",
    "    for i, mark in enumerate(state):\n",
    "        if mark == PLAYER_X:\n",
    "            update_Q(state, i, reward_x, state)\n",
    "        elif mark == PLAYER_O:\n",
    "            update_Q(state, i, reward_o, state)\n",
    "\n",
    "print(\"Q-learning training complete!\")\n",
    "\n",
    "# Play a game using the learned Q-values\n",
    "def play_with_q_learning():\n",
    "    state = [EMPTY] * 9\n",
    "    player_x_turn = True\n",
    "    while EMPTY in state:\n",
    "        if player_x_turn:\n",
    "            player = PLAYER_X\n",
    "        else:\n",
    "            player = PLAYER_O\n",
    "            \n",
    "        if player == PLAYER_X:\n",
    "            action = choose_action(state)\n",
    "        else:\n",
    "            action = random.choice([action for action, mark in enumerate(state) if mark == EMPTY])\n",
    "        \n",
    "        state[action] = player\n",
    "        print_board(state)\n",
    "        \n",
    "        if check_winner(state, player):\n",
    "            if player == PLAYER_X:\n",
    "                print(\"Player X wins!\")\n",
    "            else:\n",
    "                print(\"Player O wins!\")\n",
    "            return\n",
    "        \n",
    "        player_x_turn = not player_x_turn\n",
    "    \n",
    "    print(\"It's a draw!\")\n",
    "\n",
    "# Helper function to print the board\n",
    "def print_board(state):\n",
    "    mapping = {EMPTY: \" \", PLAYER_X: \"X\", PLAYER_O: \"O\"}\n",
    "    board = [mapping[mark] for mark in state]\n",
    "    print(f\"{board[0]}|{board[1]}|{board[2]}\\n-+-+-\\n{board[3]}|{board[4]}|{board[5]}\\n-+-+-\\n{board[6]}|{board[7]}|{board[8]}\")\n",
    "\n",
    "# Play a game using Q-learning agent\n",
    "play_with_q_learning()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22690fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
